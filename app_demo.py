import json

import streamlit as st
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.tools import StructuredTool
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import StreamlitChatMessageHistory

st.set_page_config(page_title="Team 5", page_icon="ğŸ¦œ")
st.title("ğŸ¦œğŸ”— Credit Cards Reviews")

# Set up memory
msgs = StreamlitChatMessageHistory(key="langchain_messages")
if len(msgs.messages) == 0:
    msgs.add_ai_message("How can I help you?")  # è¿™é‡Œå¯ä»¥åŠ å¼€åœºç™½

view_messages = st.expander("View the message contents in session state")

# Get an OpenAI API Key before continuing
# if "openai_api_key" in st.secrets:
#     openai_api_key = st.secrets.openai_api_key
# else:
#     openai_api_key = st.sidebar.text_input("OpenAI API Key", type="password")
# if not openai_api_key:
#     st.info("Enter an OpenAI API Key to continue")
#     st.stop()
openai_api_key = "xxx"


# def load (key) => data

# desc: æ¥å—ä¸€ä¸ªå¯ä»¥ç›´è·å–åˆ°å¯¹åº”çš„ä¿¡ç”¨å¡æ•°æ®

# def mapKeys() => 
#     return [{
#         key: 'kye1',
#         desc: "å¡ä¸€çš„ key"
#     }]
# desc : å¯ä»¥è·å–

card_map = {
    "ä¿¡ç”¨å¡1": "1",
    "ä¿¡ç”¨å¡2": "2",
    "ä¿¡ç”¨å¡3": "3"
}

def return_card_filename(card_key: str) -> str:
    if card_key in card_map:
        return card_map[card_key]
    else:
        print("error")

def load_sentiment_json_file(card_name: str):
    """
    Args:
      json_file_path: JSON æ–‡ä»¶è·¯å¾„
    """
    # # è¯»å– JSON æ–‡ä»¶
    # with open(
    #     "./Data/tools/analysis-results/" + card_name + ".json", "r", encoding="utf-8"
    # ) as f:
    #     json_data = json.load(f)
    # # print(yaml_data)
    # return "ç”¨æˆ·è¯„è®ºæ˜¯ï¼š" + str(json_data)
    print(card_name)


# def load_sentiment_json_file():
#     """
#     Args:
#       json_file_path: JSON æ–‡ä»¶è·¯å¾„
#     """
#     # è¯»å– JSON æ–‡ä»¶
#     with open("./Data/tools/analysis-results/test.json", "r", encoding="utf-8") as f:
#         json_data = json.load(f)
#     # print(yaml_data)
#     return "ç”¨æˆ·è¯„è®ºæ˜¯ï¼š" + str(json_data)

# """åˆ†æä¿¡ç”¨å¡ç›¸å…³ç”¨æˆ·è¯„è®ºæ•°æ®"""
# def analyse_origin_sentiment():
#     client = OpenAI(
#             api_key=KEY,
#         )
#         content_str = '\n'.join(d['desc'] for d in content)


#         completion = client.chat.completions.create(
#             model="gpt-3.5-turbo",
#             messages=[
#                 {
#                     "role": "system",
#                     "content": PROMPT if prompt is None else prompt,
#                 },
#                 {
#                     "role": "user",
#                     "content": content_str,
#                 }
#             ],
#         )
#         json_result = json.loads(completion.choices[0].message.content)

#         print(json_result)
#         return json_result


# Set up the LangChain, passing in Message History
agent_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are an AI chatbot having a conversation with a human."),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{question}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
        # https://python.langchain.com/docs/modules/agents/how_to/custom_agent#adding-memory
    ]
)

llm = ChatOpenAI(
    openai_api_key=openai_api_key, model="gpt-3.5-turbo", temperature=0, streaming=True
)


agent_tools = [
    StructuredTool.from_function(
        func=return_card_filename,
        name="get_card_name",
        description="æ ¹æ®ç”¨æˆ·è¾“å…¥çš„ä¿¡ç”¨å¡åç§°ï¼Œç”Ÿæˆä¸€ä¸ªé”®å€¼å¯¹keyï¼Œè¿”å›card_mapçš„å€¼valueï¼Œå¦‚æœè¿”å›çš„æ˜¯ errorï¼Œéœ€è¦ä½¿ç”¨ä¸­æ–‡æç¤ºç”¨æˆ·ï¼šè¾“å…¥é”™è¯¯ï¼Œè¯·é‡æ–°è¾“å…¥",
    ),
        StructuredTool.from_function(
        func=load_sentiment_json_file,
        name="load_file_name",
        description="card_mapçš„å€¼valueä½œä¸ºload_sentiment_json_fileå‡½æ•°å…¥å‚",
    )
]

agent = create_openai_tools_agent(llm, agent_tools, agent_prompt)
agent_executor = AgentExecutor(agent=agent, tools=agent_tools, verbose=True)

chain_with_history = RunnableWithMessageHistory(
    agent_executor,
    lambda session_id: msgs,
    input_messages_key="question",
    history_messages_key="history",
)

# Render current messages from StreamlitChatMessageHistory
for msg in msgs.messages:
    st.chat_message(msg.type).write(msg.content)

# If user inputs a new prompt, generate and draw a new response
if prompt := st.chat_input("What is up?"):
    st.chat_message("human").write(prompt)
    print(prompt)
    config = {"configurable": {"session_id": "any"}}
    response = chain_with_history.invoke({"question": prompt}, config)
    print("response is: ")
    print(response)
    st.chat_message("ai").write(response["output"])

# Draw the messages at the end, so newly generated ones show up immediately
with view_messages:
    """
    Message History initialized with:
    ```python
    msgs = StreamlitChatMessageHistory(key="langchain_messages")
    ```

    Contents of `st.session_state.langchain_messages`:
    """
    view_messages.json(st.session_state.langchain_messages)
