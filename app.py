import json

import streamlit as st
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.tools import StructuredTool
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from util import read_json_to_yaml

import pandas as pd
import numpy as np

from draw_chart import handle_openai_draw_chart


st.set_page_config(page_title="Team 5", page_icon="ğŸ¦œ")
st.title('ğŸ¦œğŸ”— Credit Cards Reviews')


def get_local_data():
    with open('data/test.json', 'r', encoding='utf-8') as file:
        return json.load(file)


data = get_local_data()


# Set up memory
msgs = StreamlitChatMessageHistory(key="langchain_messages")
if len(msgs.messages) == 0:
    msgs.add_ai_message("How can I help you?")  # è¿™é‡Œå¯ä»¥åŠ å¼€åœºç™½

view_messages = st.expander("View the message contents in session state")

# Get an OpenAI API Key before continuing
if "openai_api_key" in st.secrets:
    openai_api_key = st.secrets.openai_api_key
else:
    openai_api_key = st.sidebar.text_input("OpenAI API Key", type="password")
if not openai_api_key:
    st.info("Enter an OpenAI API Key to continue")
    st.stop()


def power(base: float, exponent: int) -> str:
    """è®¡ç®—åŸºæ•°çš„ä¹˜æ–¹å¹¶è¿”å›æ ¼å¼åŒ–å­—ç¬¦ä¸²"""
    result = base ** exponent
    return f'{base}çš„{exponent}æ¬¡æ–¹æ˜¯{result}'


def add(number1: float, number2: float) -> str:
    """è®¡ç®—ä¸¤ä¸ªæ•°çš„åŠ æ³•å¹¶è¿”å›æ ¼å¼åŒ–å­—ç¬¦ä¸²"""
    result = number1 + number2
    return f'{number1}åŠ ä¸Š{number2}çš„ç»“æœæ˜¯{result}'


def multiply(number1: float, number2: float) -> str:
    """è®¡ç®—ä¸¤ä¸ªæ•°çš„ä¹˜æ³•å¹¶è¿”å›æ ¼å¼åŒ–å­—ç¬¦ä¸²"""
    result = number1 * number2
    return f'{number1}ä¹˜ä»¥{number2}çš„ç»“æœæ˜¯{result}'

def dict_to_string(dictionary):
    return json.dumps(dictionary, indent=None)


def fetch_data(name) -> str:
    """è¿”å›ä¿¡ç”¨å¡ç›¸å…³çš„ç”¨è¯„è®ºæ•°æ®"""
    zhaohang_keywords = ["æ‹›è¡Œ", "æ‹›å•†é“¶è¡Œ"]
    nonghang_keywords = ["å†œè¡Œ", "å†œä¸šé“¶è¡Œ"]
    print(666,name)

# åˆ¤æ–­ name æ˜¯å¦åŒ…å«æ‹›å•†é“¶è¡Œç›¸å…³å…³é”®è¯
    if any(keyword in name for keyword in zhaohang_keywords):
     path = "./source-data/test.json"
    elif any(keyword in name for keyword in nonghang_keywords):
     path= "./source-data/test1.json"
    else:
     return 'error'
    data1=read_json_to_yaml(path)
    print(99999,data1)
    return "ç”¨æˆ·è¯„è®ºæ˜¯ï¼š" + str(data1)


def draw_plot(data):
    """æ¥å—json data æ•°æ®ç”»å›¾"""
    df = pd.DataFrame(data)
    with st.expander("Show data"):
        st.write(df)
    column_names = ", ".join(df.columns)
    handle_openai_draw_chart(df, column_names)
    return "done"

# Set up the LangChain, passing in Message History
agent_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are an AI chatbot having a conversation with a human."),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{question}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
    # https://python.langchain.com/docs/modules/agents/how_to/custom_agent#adding-memory
])

llm = ChatOpenAI(openai_api_key=openai_api_key, model='gpt-3.5-turbo', temperature=0, streaming=True)

agent_tools = [StructuredTool.from_function(func=add, name="add", description="Call this to get the summary"),
               StructuredTool.from_function(func=multiply, name="multiply", description="Call this to get the product"),
               StructuredTool.from_function(func=power, name="power", description="Call this to get the power"),
               StructuredTool.from_function(func=fetch_data, name="get_data",
                                            description="å¯ä»¥è·å–ä¿¡ç”¨å¡ç›¸å…³çš„ç”¨è¯„è®ºæ•°æ®"),
               StructuredTool.from_function(func=draw_plot, name="draw_plot",
                                            description="æ¥å—json data æ•°æ®ç”»å›¾"),
               ]

agent = create_openai_tools_agent(llm, agent_tools, agent_prompt)
agent_executor = AgentExecutor(agent=agent, tools=agent_tools, verbose=True)

chain_with_history = RunnableWithMessageHistory(
    agent_executor,
    lambda session_id: msgs,
    input_messages_key="question",
    history_messages_key="history",
)

# Render current messages from StreamlitChatMessageHistory
for msg in msgs.messages:
    st.chat_message(msg.type).write(msg.content)

# If user inputs a new prompt, generate and draw a new response
if prompt := st.chat_input("ä¿¡ç”¨å¡æ•°æ®ç”»å›¾"):
    st.chat_message("human").write(prompt)
    with st.spinner("Processing..."):
        print(prompt)
        config = {"configurable": {"session_id": "any"}}
        response = chain_with_history.invoke({"question": prompt}, config)
        print("response is: ")
        print(response)

        chart_data = pd.DataFrame(
            {
                "col1": np.random.randn(20),
                "col2": np.random.randn(20),
                "col3": np.random.choice(["A", "B", "C"], 20),
            }
        )

        st.chat_message("ai").write(response['output'])

# Draw the messages at the end, so newly generated ones show up immediately
with view_messages:
    """
    Message History initialized with:
    ```python
    msgs = StreamlitChatMessageHistory(key="langchain_messages")
    ```

    Contents of `st.session_state.langchain_messages`:
    """
    view_messages.json(st.session_state.langchain_messages)
