import json
from typing import Dict, List,  Any

import pandas as pd
import streamlit as st
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.tools import BaseTool, StructuredTool, tool
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.tools import StructuredTool
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from util import read_json_to_yaml, load_prompt_text

import matplotlib.pyplot as plt
from langchain.pydantic_v1 import BaseModel, Field

from draw_chart import handle_openai_draw_chart, survey

systerm_prompt = load_prompt_text()

print(systerm_prompt)

st.set_page_config(page_title="Team 5", page_icon="ğŸ¦œ")
st.title('Credit Cards Reviews')
st.set_option('deprecation.showPyplotGlobalUse', False)


# Set up memory
msgs = StreamlitChatMessageHistory(key="langchain_messages")
if len(msgs.messages) == 0:
    msgs.add_ai_message("è¯·è¾“å…¥æ‚¨æƒ³è¦äº†è§£çš„ä¿¡ç”¨å¡äº§å“å")  # è¿™é‡Œå¯ä»¥åŠ å¼€åœºç™½

# view_messages = st.expander("View the message contents in session state")

# Get an OpenAI API Key before continuing
if "openai_api_key" in st.secrets:
    openai_api_key = st.secrets.openai_api_key
else:
    openai_api_key = st.sidebar.text_input("OpenAI API Key", type="password")
if not openai_api_key:
    st.info("Enter an OpenAI API Key to continue")
    st.stop()


def dict_to_string(dictionary):
    return json.dumps(dictionary, indent=None)


CARD_MAP = {"æ‹›å•†é“¶è¡Œç»å…¸ç™½é‡‘å¡": "file_1", "ä¸‡äº‹è¾¾": "file_2"}


def fetch_data(card_key: str) -> str:
    if card_key in CARD_MAP:
        return load_json(CARD_MAP[card_key])
    else:
        print("fetch_dataæ²¡æœ‰æ‰¾åˆ°å¯¹åº”æ•°æ®")


def load_json(card_name: str):
    """
    Args:
      json_file_path: JSON æ–‡ä»¶è·¯å¾„
    """
    # è¯»å– JSON æ–‡ä»¶
    with open(
            "./Data/tools/analysis-results/" + card_name + ".json", "r", encoding="utf-8"
    ) as f:
        json_data = json.load(f)
    # print(yaml_data)
    st.spinner("è·å–åˆ°äº†æ•°æ®ï¼Œæ­£åœ¨åˆ†æ...")
    return "è¿”å›çš„æ˜¯json dataï¼Œæ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œä¸€ä¸ªå¯¹è±¡å°±æ˜¯å¯¹ä¸€ä¸ªç”¨æˆ·è¯„è®ºçš„åˆ†æç»“æœã€‚ç”¨æˆ·ä¿¡ç”¨å¡ç›¸å…³çš„è¯„è®ºï¼Œæƒ…æ„Ÿåˆ†æåçš„æ•°æ®æ˜¯ï¼š" + str(json_data)


class DrawBarChart_Model(BaseModel):
    category_names: List[str] = Field(description="list of str The category labels. category is the emotions list: 'positive', 'negative', 'neutral'")
    map_data: Dict[str, List[int]] = Field(
        description="ä¼ å…¥å¯¹ä¿¡ç”¨å¡æ•°æ®ç»Ÿè®¡é›†åˆï¼Œè¾“å‡ºDict[str, List[int]]çš„python ç»“æ„ä½“ï¼š{'Card Costs': [5, 5, 5], 'Rewards Program': [3, 5, 7], 'Customer Service': [5, 4, 6], 'App Usability': [4, 8, 3], 'Benefits': [1, 7, 7]}")


# def draw_plot_func(category_names: List[str], map_data: Dict[str, List[int]]) -> str:
def draw_bar_chart(category_names: List[str], map_data: Dict[str, List[int]]) -> str:
    """
    draw a horizontal chart
    """
    category_names = category_names
    map_data = map_data
    print("æ‰§è¡Œäº†draw_plot")
    print(category_names)
    print(map_data)
    message = st.chat_message("assistant")
    tab1, tab2 = message.tabs(["ğŸ“ˆ Chart", "ğŸ—ƒ Data"])
    tab1.subheader("ç»´åº¦æƒ…æ„Ÿåˆ†ææ°´å¹³æŸ±çŠ¶å›¾")
    # category_names = ['positive', 'negative', 'neutral']
    # arr_data = {'Card Costs': [5, 5, 5], 'Rewards Program': [3, 5, 7], 'Customer Service': [5, 4, 6], 'App Usability': [4, 8, 3], 'Benefits': [1, 7, 7]}
    survey(map_data, category_names)
    plt.show()
    tab1.pyplot()

    tab2.subheader("æ•°æ®Table")
    # åˆ›å»º DataFrame
    table_data = pd.DataFrame.from_dict(map_data, orient='index', columns=category_names)
    tab2.write(table_data)
    return "å›¾å’Œè¡¨éƒ½å±•ç¤ºå®Œæˆäº†"


# Set up the LangChain, passing in Message History
agent_prompt = ChatPromptTemplate.from_messages([
    ("system", systerm_prompt),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{question}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
    # https://python.langchain.com/docs/modules/agents/how_to/custom_agent#adding-memory
])

llm = ChatOpenAI(
    openai_api_key=openai_api_key, model="gpt-4-turbo-preview", temperature=0, streaming=True
)


class DrawGeneralPlot_Model(BaseModel):
    chart_desc_text: str = Field(description="ç”¨æˆ·æƒ³ç”»ä»€ä¹ˆå›¾ï¼Œä¼ å…¥è‹±æ–‡")
    data: str = Field(
        description="ä¼ å…¥å¯¹ä¿¡ç”¨å¡æ•°æ®ç»Ÿè®¡é›†åˆå³å¯ï¼Œå¹¶å­—æ®µé™„å¸¦æè¿°å’Œå«ä¹‰}")


agent_tools = [
    StructuredTool.from_function(func=fetch_data, name="fetch_data",
                                 description=f"å¯ä»¥è·å–ç”¨æˆ·ä¿¡ç”¨å¡ç›¸å…³çš„è¯„è®ºï¼Œæƒ…æ„Ÿåˆ†æåçš„æ•°æ®ã€‚è¯·æ ¹æ®è¾“å…¥ä¿¡ç”¨å¡å…³é”®å­—è‡ªåŠ¨mapä¼ å…¥ï¼Œmapæ•°æ®æ˜¯{dict_to_string(CARD_MAP)}"),
    StructuredTool.from_function(func=handle_openai_draw_chart, name="draw_general_plot",
                                 args_schema=DrawGeneralPlot_Model,
                                 description="æ ¹æ®æè¿°ï¼Œç”»å›¾ï¼Œè¦ä¼ å…¥ç”¨æˆ·è¯„è®ºæƒ…æ„Ÿåˆ†ææ•°æ®ç»Ÿè®¡åçš„æ•°æ®é›†å’Œæè¿°ï¼Œè¦ç”»ä»€ä¹ˆå›¾è¯·æå‰å…³é”®å­—å¹¶ç¿»è¯‘æˆè‹±æ–‡ä¼ å…¥"),
    StructuredTool.from_function(func=draw_bar_chart, name="draw_bar_chart",
                                 # args_schema=DrawPlot_Model,
                                 description="å½“ç”¨æˆ·æƒ³è¦æŸ±çŠ¶å›¾æ—¶ï¼Œä½¿ç”¨è¿™ä¸ªå·¥å…·ç”»å›¾ï¼Œcould draw a chartï¼Œgiven: { 'category_names': ['positive', 'negative', 'neutral'],'map_data': {'CardCosts': [5, 5, 5], 'RewardsProgram': [3, 5, 7], 'CustomerService': [5, 4, 6], 'AppUsability': [4, 8, 3], 'Benefits': [1, 7, 7]}} as parmas then it could draw horizontal bar chart"),

]

agent = create_openai_tools_agent(llm, agent_tools, agent_prompt)
agent_executor = AgentExecutor(agent=agent, tools=agent_tools, verbose=True)

chain_with_history = RunnableWithMessageHistory(
    agent_executor,
    lambda session_id: msgs,
    input_messages_key="question",
    history_messages_key="history",
)

# Render current messages from StreamlitChatMessageHistory
for msg in msgs.messages:
    st.chat_message(msg.type).write(msg.content)

# If user inputs a new prompt, generate and draw a new response
if prompt := st.chat_input("ä½ å¯ä»¥è¾“å‡ºä¸€ä¸ªä¿¡ç”¨å¡ï¼šæ¯”å¦‚æ‹›è¡Œä¿¡ç”¨å¡"):
    st.chat_message("human").write(prompt)
    with st.spinner("Processing..."):
        print(prompt)
        config = {"configurable": {"session_id": "any"}}
        response = chain_with_history.invoke({"question": prompt}, config)
        print("response is: ")
        print(response)

        st.chat_message("ai").write(response["output"])

# Draw the messages at the end, so newly generated ones show up immediately
# with view_messages:
#     """
#     Message History initialized with:
#     ```python
#     msgs = StreamlitChatMessageHistory(key="langchain_messages")
#     ```
#
#     Contents of `st.session_state.langchain_messages`:
#     """
#     view_messages.json(st.session_state.langchain_messages)

